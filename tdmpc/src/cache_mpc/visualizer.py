import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import networkx as nx
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import mean_absolute_error
from dtaidistance import dtw
from matplotlib.patches import Rectangle
import matplotlib.patches as mpatches
from matplotlib.collections import LineCollection
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.style.use('default')

class CacheMPCVisualizer:
    """Cache MPC ä¸“ç”¨å¯è§†åŒ–å·¥å…·ç±»"""
    
    def __init__(self, horizon, action_dim):
        self.horizon = horizon
        self.action_dim = action_dim
        self.colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', 
                      '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']
    
    def load_planned_actions_data(self, test_dir, episode_num=1, max_time_steps=10):
        """ä»CSVæ–‡ä»¶åŠ è½½è½¨è¿¹æ•°æ®"""
        import os
        import glob
        
        episode_dir = f"{test_dir}/episode_{episode_num}"
        csv_files = glob.glob(f"{episode_dir}/planned-actions-time*.csv")
        
        trajectories_data = {}
        for csv_file in sorted(csv_files)[:max_time_steps]:
            # æå–æ—¶é—´æ­¥
            filename = os.path.basename(csv_file)
            time_step = int(filename.split('time')[1].split('.')[0])
            
            # è¯»å–CSVæ•°æ®
            df = pd.read_csv(csv_file)
            
            # æå–è½¨è¿¹åºåˆ—
            trajectories = []
            for _, row in df.iterrows():
                trajectory = []
                for h in range(self.horizon):
                    for a in range(self.action_dim):
                        col_name = f't{time_step + h + 1}_action{a}'
                        if col_name in df.columns:
                            trajectory.append(row[col_name])
                trajectories.append(np.array(trajectory))
            
            trajectories_data[time_step] = {
                'trajectories': np.array(trajectories),
                'values': df['value'].values,
                'scores': df['score'].values
            }
        
        return trajectories_data
    
    def trajectory_bundle_visualization(self, trajectories_data, save_path=None, 
                                      show_top_k=5, action_dim_to_plot=0):
        """
        1. è½¨è¿¹æŸå¯è§†åŒ– (Trajectory Bundle)
        å±•ç¤ºå¤šæ¡è½¨è¿¹çš„temporal evolutionå’Œé‡å æ¨¡å¼
        """
        fig, axes = plt.subplots(2, 2, figsize=(16, 10))
        
        time_steps = sorted(trajectories_data.keys())
        
        # 1.1 å•ä¸ªæ—¶é—´æ­¥çš„è½¨è¿¹æŸ (å·¦ä¸Š)
        ax1 = axes[0, 0]
        
        if time_steps:
            first_time = time_steps[0]
            data = trajectories_data[first_time]
            trajs = data['trajectories']
            values = data['values']
            
            # é€‰æ‹©top-ké«˜ä»·å€¼è½¨è¿¹
            top_indices = np.argsort(values)[-show_top_k:]
            
            horizon_steps = np.arange(self.horizon)
            
            for i, idx in enumerate(top_indices):
                # æå–ç¬¬ä¸€ä¸ªåŠ¨ä½œç»´åº¦çš„è½¨è¿¹
                traj_1d = trajs[idx].reshape(self.horizon, self.action_dim)[:, action_dim_to_plot]
                
                alpha = 0.8 if i == len(top_indices)-1 else 0.6  # æœ€é«˜ä»·å€¼è½¨è¿¹æ›´çªå‡º
                linewidth = 3 if i == len(top_indices)-1 else 2
                
                ax1.plot(horizon_steps, traj_1d, 
                        color=self.colors[i % len(self.colors)], 
                        alpha=alpha, linewidth=linewidth,
                        label=f'è½¨è¿¹ {idx+1} (v={values[idx]:.3f})')
            
            ax1.set_xlabel('è§„åˆ’æ­¥éª¤')
            ax1.set_ylabel(f'åŠ¨ä½œç»´åº¦ {action_dim_to_plot}')
            ax1.set_title(f'æ—¶é—´æ­¥ {first_time} - Top {show_top_k} è½¨è¿¹æŸ')
            ax1.legend(loc='best', fontsize=9)
            ax1.grid(True, alpha=0.3)
        
        # 1.2 å¤šæ—¶é—´æ­¥è½¨è¿¹æ¼”åŒ– (å³ä¸Š)
        ax2 = axes[0, 1]
        
        # é€‰æ‹©æ¯ä¸ªæ—¶é—´æ­¥çš„æœ€ä½³è½¨è¿¹è¿›è¡Œå¯¹æ¯”
        best_trajectories = []
        time_labels = []
        
        for t in time_steps[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªæ—¶é—´æ­¥
            data = trajectories_data[t]
            best_idx = np.argmax(data['values'])
            best_traj = data['trajectories'][best_idx].reshape(self.horizon, self.action_dim)
            
            ax2.plot(np.arange(self.horizon), best_traj[:, action_dim_to_plot],
                    color=self.colors[t % len(self.colors)], 
                    linewidth=2, alpha=0.8, label=f't={t}')
        
        ax2.set_xlabel('è§„åˆ’æ­¥éª¤')
        ax2.set_ylabel(f'åŠ¨ä½œç»´åº¦ {action_dim_to_plot}')
        ax2.set_title('æœ€ä¼˜è½¨è¿¹çš„æ—¶åºæ¼”åŒ–')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 1.3 è½¨è¿¹é‡å åŒºåŸŸå¯è§†åŒ– (å·¦ä¸‹)
        ax3 = axes[1, 0]
        
        if len(time_steps) >= 2:
            t1, t2 = time_steps[0], time_steps[1]
            data1, data2 = trajectories_data[t1], trajectories_data[t2]
            
            # é€‰æ‹©ä¸¤ä¸ªæ—¶é—´æ­¥çš„æœ€ä½³è½¨è¿¹
            best_idx1 = np.argmax(data1['values'])
            best_idx2 = np.argmax(data2['values'])
            
            traj1 = data1['trajectories'][best_idx1].reshape(self.horizon, self.action_dim)
            traj2 = data2['trajectories'][best_idx2].reshape(self.horizon, self.action_dim)
            
            horizon_steps = np.arange(self.horizon)
            
            # ç»˜åˆ¶ä¸¤æ¡è½¨è¿¹
            line1 = ax3.plot(horizon_steps, traj1[:, action_dim_to_plot], 
                           'b-', linewidth=3, label=f'æ—¶é—´æ­¥ {t1}')[0]
            line2 = ax3.plot(horizon_steps, traj2[:, action_dim_to_plot], 
                           'r-', linewidth=3, label=f'æ—¶é—´æ­¥ {t2}')[0]
            
            # å¡«å……é‡å åŒºåŸŸ
            ax3.fill_between(horizon_steps, 
                           traj1[:, action_dim_to_plot], 
                           traj2[:, action_dim_to_plot],
                           alpha=0.3, color='yellow', label='å·®å¼‚åŒºåŸŸ')
            
            # è®¡ç®—MAEå·®å¼‚
            mae_diff = mean_absolute_error(traj1[:, action_dim_to_plot], 
                                         traj2[:, action_dim_to_plot])
            ax3.text(0.02, 0.98, f'MAEå·®å¼‚: {mae_diff:.4f}', 
                    transform=ax3.transAxes, verticalalignment='top',
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
            
            ax3.set_xlabel('è§„åˆ’æ­¥éª¤')
            ax3.set_ylabel(f'åŠ¨ä½œç»´åº¦ {action_dim_to_plot}')
            ax3.set_title('ç›¸é‚»æ—¶é—´æ­¥è½¨è¿¹é‡å åˆ†æ')
            ax3.legend()
            ax3.grid(True, alpha=0.3)
        
        # 1.4 è½¨è¿¹æŸç»Ÿè®¡ä¿¡æ¯ (å³ä¸‹)
        ax4 = axes[1, 1]
        
        # è®¡ç®—æ¯ä¸ªæ—¶é—´æ­¥çš„è½¨è¿¹å¤šæ ·æ€§æŒ‡æ ‡
        diversity_metrics = []
        time_points = []
        
        for t in time_steps:
            data = trajectories_data[t]
            trajs = data['trajectories']
            
            # è®¡ç®—è½¨è¿¹é—´çš„å¹³å‡MAEè·ç¦»
            n_trajs = len(trajs)
            total_distance = 0
            count = 0
            
            for i in range(n_trajs):
                for j in range(i+1, n_trajs):
                    distance = mean_absolute_error(trajs[i], trajs[j])
                    total_distance += distance
                    count += 1
            
            avg_diversity = total_distance / count if count > 0 else 0
            diversity_metrics.append(avg_diversity)
            time_points.append(t)
        
        ax4.plot(time_points, diversity_metrics, 'go-', linewidth=2, markersize=8)
        ax4.set_xlabel('æ—¶é—´æ­¥')
        ax4.set_ylabel('å¹³å‡è½¨è¿¹å¤šæ ·æ€§ (MAE)')
        ax4.set_title('è½¨è¿¹æŸå¤šæ ·æ€§éšæ—¶é—´å˜åŒ–')
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.suptitle('è½¨è¿¹æŸå¯è§†åŒ– - Cache MPC é‡å åˆ†æ', fontsize=16, y=0.98)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        
        return fig
    
    def similarity_network_visualization(self, trajectories_data, 
                                       similarity_threshold=0.8, save_path=None):
        """
        2. ç›¸ä¼¼æ€§ç½‘ç»œå›¾ (Similarity Network)
        å°†è½¨è¿¹ä½œä¸ºèŠ‚ç‚¹ï¼Œç›¸ä¼¼æ€§ä½œä¸ºè¾¹ï¼Œç›´è§‚æ˜¾ç¤ºé‡ç”¨å…³ç³»
        """
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        time_steps = sorted(trajectories_data.keys())
        
        # 2.1 å•æ—¶é—´æ­¥å†…çš„è½¨è¿¹ç›¸ä¼¼æ€§ç½‘ç»œ (å·¦ä¸Š)
        ax1 = axes[0, 0]
        
        if time_steps:
            first_time = time_steps[0]
            data = trajectories_data[first_time]
            trajs = data['trajectories'][:10]  # åªå–å‰10ä¸ªè½¨è¿¹é¿å…è¿‡äºå¤æ‚
            values = data['values'][:10]
            
            # è®¡ç®—ç›¸ä¼¼æ€§çŸ©é˜µ (ä½¿ç”¨è´ŸMAEä½œä¸ºç›¸ä¼¼æ€§)
            n_trajs = len(trajs)
            similarity_matrix = np.zeros((n_trajs, n_trajs))
            
            for i in range(n_trajs):
                for j in range(n_trajs):
                    if i == j:
                        similarity_matrix[i, j] = 1.0
                    else:
                        mae_dist = mean_absolute_error(trajs[i], trajs[j])
                        # è½¬æ¢ä¸ºç›¸ä¼¼æ€§ (è·ç¦»è¶Šå°ï¼Œç›¸ä¼¼æ€§è¶Šé«˜)
                        similarity_matrix[i, j] = 1 / (1 + mae_dist)
            
            # åˆ›å»ºç½‘ç»œå›¾
            G = nx.Graph()
            
            # æ·»åŠ èŠ‚ç‚¹ (è½¨è¿¹)
            for i in range(n_trajs):
                G.add_node(i, value=values[i])
            
            # æ·»åŠ è¾¹ (ç›¸ä¼¼æ€§è¶…è¿‡é˜ˆå€¼çš„è½¨è¿¹å¯¹)
            edges_added = []
            for i in range(n_trajs):
                for j in range(i+1, n_trajs):
                    if similarity_matrix[i, j] > similarity_threshold:
                        G.add_edge(i, j, weight=similarity_matrix[i, j])
                        edges_added.append((i, j, similarity_matrix[i, j]))
            
            if len(G.nodes()) > 0:
                # ä½¿ç”¨spring layout
                pos = nx.spring_layout(G, k=2, iterations=50, seed=42)
                
                # ç»˜åˆ¶è¾¹
                edges = G.edges()
                edge_weights = [G[u][v]['weight'] for u, v in edges]
                
                nx.draw_networkx_edges(G, pos, ax=ax1, alpha=0.6, 
                                     width=[w*3 for w in edge_weights],
                                     edge_color='gray')
                
                # ç»˜åˆ¶èŠ‚ç‚¹ - å¤§å°æ ¹æ®ä»·å€¼ï¼Œé¢œè‰²æ ¹æ®ä»·å€¼
                node_sizes = [300 + v*200 for v in values]  # åŸºç¡€å¤§å°300ï¼Œæ ¹æ®ä»·å€¼è°ƒæ•´
                node_colors = values
                
                nodes = nx.draw_networkx_nodes(G, pos, ax=ax1,
                                             node_size=node_sizes,
                                             node_color=node_colors,
                                             cmap='viridis', alpha=0.8)
                
                # æ·»åŠ èŠ‚ç‚¹æ ‡ç­¾
                nx.draw_networkx_labels(G, pos, ax=ax1, font_size=8, font_weight='bold')
                
                # æ·»åŠ è¾¹æƒé‡æ ‡ç­¾ (åªæ˜¾ç¤ºæƒé‡é«˜çš„è¾¹)
                edge_labels = {(i, j): f'{w:.3f}' 
                             for i, j, w in edges_added if w > similarity_threshold + 0.05}
                nx.draw_networkx_edge_labels(G, pos, edge_labels, 
                                           font_size=7, ax=ax1)
                
                # æ·»åŠ é¢œè‰²æ¡
                if nodes:
                    cbar = plt.colorbar(nodes, ax=ax1)
                    cbar.set_label('è½¨è¿¹ä»·å€¼', rotation=270, labelpad=15)
            
            ax1.set_title(f'æ—¶é—´æ­¥ {first_time} è½¨è¿¹ç›¸ä¼¼æ€§ç½‘ç»œ\n(é˜ˆå€¼ > {similarity_threshold})')
            ax1.axis('off')
        
        # 2.2 è·¨æ—¶é—´æ­¥çš„è½¨è¿¹é‡ç”¨ç½‘ç»œ (å³ä¸Š)
        ax2 = axes[0, 1]
        
        if len(time_steps) >= 2:
            # åˆ›å»ºè·¨æ—¶é—´æ­¥çš„ç½‘ç»œ
            G_temporal = nx.Graph()
            
            # æ”¶é›†æ‰€æœ‰è½¨è¿¹æ•°æ®
            all_trajectories = []
            all_values = []
            all_time_labels = []
            trajectory_ids = []
            
            for t_idx, t in enumerate(time_steps[:3]):  # åªç”¨å‰3ä¸ªæ—¶é—´æ­¥
                data = trajectories_data[t]
                top_indices = np.argsort(data['values'])[-5:]  # æ¯ä¸ªæ—¶é—´æ­¥å–top5
                
                for local_idx, global_idx in enumerate(top_indices):
                    node_id = f"t{t}_traj{local_idx}"
                    trajectory_ids.append(node_id)
                    all_trajectories.append(data['trajectories'][global_idx])
                    all_values.append(data['values'][global_idx])
                    all_time_labels.append(t)
                    G_temporal.add_node(node_id, time=t, value=data['values'][global_idx])
            
            # è®¡ç®—è·¨æ—¶é—´çš„ç›¸ä¼¼æ€§å¹¶æ·»åŠ è¾¹
            for i in range(len(all_trajectories)):
                for j in range(i+1, len(all_trajectories)):
                    # åªè¿æ¥ä¸åŒæ—¶é—´æ­¥çš„è½¨è¿¹
                    if all_time_labels[i] != all_time_labels[j]:
                        mae_dist = mean_absolute_error(all_trajectories[i], all_trajectories[j])
                        similarity = 1 / (1 + mae_dist)
                        
                        if similarity > similarity_threshold:
                            G_temporal.add_edge(trajectory_ids[i], trajectory_ids[j], 
                                              weight=similarity)
            
            if len(G_temporal.nodes()) > 0:
                # ä½¿ç”¨åˆ†å±‚å¸ƒå±€
                pos_temporal = {}
                time_positions = {t: idx for idx, t in enumerate(sorted(set(all_time_labels)))}
                
                # ä¸ºæ¯ä¸ªæ—¶é—´æ­¥çš„èŠ‚ç‚¹åˆ†é…ä½ç½®
                for node in G_temporal.nodes():
                    time_step = G_temporal.nodes[node]['time']
                    x = time_positions[time_step] * 3  # æ—¶é—´æ­¥é—´è·
                    
                    # åŒä¸€æ—¶é—´æ­¥å†…çš„èŠ‚ç‚¹å‚ç›´åˆ†å¸ƒ
                    same_time_nodes = [n for n in G_temporal.nodes() 
                                     if G_temporal.nodes[n]['time'] == time_step]
                    y_offset = same_time_nodes.index(node) - len(same_time_nodes)/2
                    y = y_offset * 0.8
                    
                    pos_temporal[node] = (x, y)
                
                # ç»˜åˆ¶è¾¹
                edge_weights_temporal = [G_temporal[u][v]['weight'] for u, v in G_temporal.edges()]
                nx.draw_networkx_edges(G_temporal, pos_temporal, ax=ax2, alpha=0.6,
                                     width=[w*4 for w in edge_weights_temporal],
                                     edge_color='red')
                
                # ç»˜åˆ¶èŠ‚ç‚¹
                node_colors_temporal = [G_temporal.nodes[node]['value'] for node in G_temporal.nodes()]
                node_times = [G_temporal.nodes[node]['time'] for node in G_temporal.nodes()]
                
                # æ ¹æ®æ—¶é—´æ­¥ä½¿ç”¨ä¸åŒå½¢çŠ¶
                for time_step in set(node_times):
                    time_nodes = [node for node in G_temporal.nodes() 
                                if G_temporal.nodes[node]['time'] == time_step]
                    time_pos = {node: pos_temporal[node] for node in time_nodes}
                    time_colors = [G_temporal.nodes[node]['value'] for node in time_nodes]
                    
                    markers = ['o', 's', '^']  # åœ†å½¢ã€æ–¹å½¢ã€ä¸‰è§’å½¢
                    marker = markers[time_step % len(markers)]
                    
                    nx.draw_networkx_nodes(G_temporal, time_pos, nodelist=time_nodes,
                                         node_color=time_colors, node_shape=marker,
                                         node_size=200, cmap='plasma', alpha=0.8, ax=ax2)
                
                # æ·»åŠ æ ‡ç­¾
                nx.draw_networkx_labels(G_temporal, pos_temporal, ax=ax2, font_size=6)
            
            ax2.set_title('è·¨æ—¶é—´æ­¥è½¨è¿¹é‡ç”¨ç½‘ç»œ')
            ax2.axis('off')
        
        # 2.3 ç›¸ä¼¼æ€§åˆ†å¸ƒç›´æ–¹å›¾ (å·¦ä¸‹)
        ax3 = axes[1, 0]
        
        all_similarities = []
        
        for t in time_steps[:3]:  # åˆ†æå‰3ä¸ªæ—¶é—´æ­¥
            data = trajectories_data[t]
            trajs = data['trajectories'][:10]  # å‰10ä¸ªè½¨è¿¹
            
            for i in range(len(trajs)):
                for j in range(i+1, len(trajs)):
                    mae_dist = mean_absolute_error(trajs[i], trajs[j])
                    similarity = 1 / (1 + mae_dist)
                    all_similarities.append(similarity)
        
        ax3.hist(all_similarities, bins=30, alpha=0.7, color='skyblue', 
                edgecolor='black', density=True)
        ax3.axvline(similarity_threshold, color='red', linestyle='--', linewidth=2,
                   label=f'é˜ˆå€¼ = {similarity_threshold}')
        ax3.axvline(np.mean(all_similarities), color='green', linestyle='--', linewidth=2,
                   label=f'å¹³å‡å€¼ = {np.mean(all_similarities):.3f}')
        
        ax3.set_xlabel('ç›¸ä¼¼æ€§å¾—åˆ†')
        ax3.set_ylabel('å¯†åº¦')
        ax3.set_title('è½¨è¿¹ç›¸ä¼¼æ€§åˆ†å¸ƒ')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 2.4 ç½‘ç»œç»Ÿè®¡ä¿¡æ¯ (å³ä¸‹)
        ax4 = axes[1, 1]
        
        # åˆ†æä¸åŒé˜ˆå€¼ä¸‹çš„ç½‘ç»œè¿é€šæ€§
        thresholds = np.arange(0.5, 1.0, 0.05)
        connectivity_stats = []
        
        for threshold in thresholds:
            if time_steps:
                first_time = time_steps[0]
                data = trajectories_data[first_time]
                trajs = data['trajectories'][:10]
                
                # åˆ›å»ºä¸´æ—¶ç½‘ç»œ
                temp_G = nx.Graph()
                temp_G.add_nodes_from(range(len(trajs)))
                
                for i in range(len(trajs)):
                    for j in range(i+1, len(trajs)):
                        mae_dist = mean_absolute_error(trajs[i], trajs[j])
                        similarity = 1 / (1 + mae_dist)
                        if similarity > threshold:
                            temp_G.add_edge(i, j)
                
                # è®¡ç®—è¿é€šæ€§ç»Ÿè®¡
                num_edges = temp_G.number_of_edges()
                num_components = nx.number_connected_components(temp_G)
                max_component_size = max([len(c) for c in nx.connected_components(temp_G)]) if num_edges > 0 else 1
                
                connectivity_stats.append({
                    'threshold': threshold,
                    'edges': num_edges,
                    'components': num_components,
                    'max_component': max_component_size
                })
        
        if connectivity_stats:
            stats_df = pd.DataFrame(connectivity_stats)
            
            ax4_twin = ax4.twinx()
            
            line1 = ax4.plot(stats_df['threshold'], stats_df['edges'], 'b-o', 
                           label='è¾¹æ•°é‡', linewidth=2, markersize=6)
            line2 = ax4_twin.plot(stats_df['threshold'], stats_df['max_component'], 'r-s',
                                label='æœ€å¤§è¿é€šåˆ†é‡', linewidth=2, markersize=6)
            
            ax4.set_xlabel('ç›¸ä¼¼æ€§é˜ˆå€¼')
            ax4.set_ylabel('è¾¹æ•°é‡', color='blue')
            ax4_twin.set_ylabel('æœ€å¤§è¿é€šåˆ†é‡å¤§å°', color='red')
            ax4.set_title('ç½‘ç»œè¿é€šæ€§ vs ç›¸ä¼¼æ€§é˜ˆå€¼')
            
            # åˆå¹¶å›¾ä¾‹
            lines1, labels1 = ax4.get_legend_handles_labels()
            lines2, labels2 = ax4_twin.get_legend_handles_labels()
            ax4.legend(lines1 + lines2, labels1 + labels2, loc='upper left')
            
            ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.suptitle('è½¨è¿¹ç›¸ä¼¼æ€§ç½‘ç»œåˆ†æ - Cache MPC', fontsize=16, y=0.98)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        
        return fig
    
    def temporal_overlap_heatmap(self, trajectories_data, save_path=None, window_size=3):
        """
        4. æ—¶åºé‡å çƒ­å›¾
        æ˜¾ç¤ºä¸åŒæ—¶é—´çª—å£çš„é‡å æƒ…å†µï¼Œå¸®åŠ©ç¡®å®šæœ€ä½³ç¼“å­˜æ—¶æœº
        """
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        time_steps = sorted(trajectories_data.keys())
        
        # 4.1 æ—¶é—´æ­¥é—´çš„å…¨å±€ç›¸ä¼¼æ€§çƒ­å›¾ (å·¦ä¸Š)
        ax1 = axes[0, 0]
        
        if len(time_steps) >= 2:
            n_times = len(time_steps)
            global_similarity_matrix = np.zeros((n_times, n_times))
            
            for i, t1 in enumerate(time_steps):
                for j, t2 in enumerate(time_steps):
                    if i == j:
                        global_similarity_matrix[i, j] = 1.0
                    else:
                        data1 = trajectories_data[t1]
                        data2 = trajectories_data[t2]
                        
                        # é€‰æ‹©æœ€ä¼˜è½¨è¿¹è¿›è¡Œæ¯”è¾ƒ
                        best_idx1 = np.argmax(data1['values'])
                        best_idx2 = np.argmax(data2['values'])
                        
                        best_traj1 = data1['trajectories'][best_idx1]
                        best_traj2 = data2['trajectories'][best_idx2]
                        
                        mae_dist = mean_absolute_error(best_traj1, best_traj2)
                        similarity = 1 / (1 + mae_dist)
                        global_similarity_matrix[i, j] = similarity
            
            im1 = ax1.imshow(global_similarity_matrix, cmap='Blues', aspect='auto', 
                           vmin=0, vmax=1)
            
            # æ·»åŠ æ•°å€¼æ ‡æ³¨
            for i in range(n_times):
                for j in range(n_times):
                    text_color = 'white' if global_similarity_matrix[i, j] > 0.5 else 'black'
                    ax1.text(j, i, f'{global_similarity_matrix[i, j]:.3f}',
                           ha="center", va="center", color=text_color, fontsize=9)
            
            ax1.set_xticks(range(n_times))
            ax1.set_yticks(range(n_times))
            ax1.set_xticklabels([f't={t}' for t in time_steps])
            ax1.set_yticklabels([f't={t}' for t in time_steps])
            ax1.set_xlabel('æ—¶é—´æ­¥ j')
            ax1.set_ylabel('æ—¶é—´æ­¥ i')
            ax1.set_title('æ—¶é—´æ­¥é—´æœ€ä¼˜è½¨è¿¹ç›¸ä¼¼æ€§')
            
            plt.colorbar(im1, ax=ax1, label='ç›¸ä¼¼æ€§å¾—åˆ†')
        
        # 4.2 æ»‘åŠ¨çª—å£é‡å åˆ†æ (å³ä¸Š)
        ax2 = axes[0, 1]
        
        if len(time_steps) >= window_size:
            window_overlaps = []
            window_centers = []
            
            for i in range(len(time_steps) - window_size + 1):
                window_times = time_steps[i:i + window_size]
                window_center = np.mean(window_times)
                
                # è®¡ç®—çª—å£å†…æ‰€æœ‰è½¨è¿¹å¯¹çš„å¹³å‡ç›¸ä¼¼æ€§
                window_similarities = []
                
                for t1 in window_times:
                    for t2 in window_times:
                        if t1 != t2:
                            data1 = trajectories_data[t1]
                            data2 = trajectories_data[t2]
                            
                            # è®¡ç®—topè½¨è¿¹é—´çš„ç›¸ä¼¼æ€§
                            top_indices1 = np.argsort(data1['values'])[-3:]  # top 3
                            top_indices2 = np.argsort(data2['values'])[-3:]  # top 3
                            
                            for idx1 in top_indices1:
                                for idx2 in top_indices2:
                                    mae_dist = mean_absolute_error(
                                        data1['trajectories'][idx1],
                                        data2['trajectories'][idx2]
                                    )
                                    similarity = 1 / (1 + mae_dist)
                                    window_similarities.append(similarity)
                
                avg_similarity = np.mean(window_similarities) if window_similarities else 0
                window_overlaps.append(avg_similarity)
                window_centers.append(window_center)
            
            ax2.plot(window_centers, window_overlaps, 'ro-', linewidth=3, markersize=8)
            ax2.fill_between(window_centers, window_overlaps, alpha=0.3, color='red')
            
            ax2.set_xlabel('çª—å£ä¸­å¿ƒæ—¶é—´')
            ax2.set_ylabel('å¹³å‡ç›¸ä¼¼æ€§')
            ax2.set_title(f'æ»‘åŠ¨çª—å£é‡å åˆ†æ (çª—å£å¤§å°={window_size})')
            ax2.grid(True, alpha=0.3)
        
        # 4.3 ç¼“å­˜å‘½ä¸­ç‡é¢„æµ‹çƒ­å›¾ (å·¦ä¸‹)
        ax3 = axes[1, 0]
        
        # æ¨¡æ‹Ÿç¼“å­˜å‘½ä¸­ç‡çŸ©é˜µ
        cache_hit_matrix = np.zeros((len(time_steps), len(time_steps)))
        
        for i, t_cache in enumerate(time_steps):  # ç¼“å­˜æ—¶é—´
            for j, t_query in enumerate(time_steps):  # æŸ¥è¯¢æ—¶é—´
                if i <= j:  # åªèƒ½ä½¿ç”¨è¿‡å»çš„ç¼“å­˜
                    # åŸºäºç›¸ä¼¼æ€§è®¡ç®—å‘½ä¸­ç‡
                    if i < len(time_steps) and j < len(time_steps):
                        time_gap = t_query - t_cache
                        
                        # æ—¶é—´é—´éš”è¶Šå¤§ï¼Œå‘½ä¸­ç‡è¶Šä½
                        decay_factor = np.exp(-time_gap * 0.1)
                        
                        if t_cache in trajectories_data and t_query in trajectories_data:
                            data_cache = trajectories_data[t_cache]
                            data_query = trajectories_data[t_query]
                            
                            best_idx_cache = np.argmax(data_cache['values'])
                            best_idx_query = np.argmax(data_query['values'])
                            
                            mae_dist = mean_absolute_error(
                                data_cache['trajectories'][best_idx_cache],
                                data_query['trajectories'][best_idx_query]
                            )
                            similarity = 1 / (1 + mae_dist)
                            
                            cache_hit_rate = similarity * decay_factor
                            cache_hit_matrix[i, j] = cache_hit_rate
        
        im3 = ax3.imshow(cache_hit_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)
        
        ax3.set_xticks(range(len(time_steps)))
        ax3.set_yticks(range(len(time_steps)))
        ax3.set_xticklabels([f't={t}' for t in time_steps])
        ax3.set_yticklabels([f't={t}' for t in time_steps])
        ax3.set_xlabel('æŸ¥è¯¢æ—¶é—´')
        ax3.set_ylabel('ç¼“å­˜æ—¶é—´')
        ax3.set_title('ç¼“å­˜å‘½ä¸­ç‡é¢„æµ‹çŸ©é˜µ')
        
        plt.colorbar(im3, ax=ax3, label='é¢„æµ‹å‘½ä¸­ç‡')
        
        # 4.4 æœ€ä½³ç¼“å­˜æ—¶æœºåˆ†æ (å³ä¸‹)
        ax4 = axes[1, 1]
        
        # è®¡ç®—æ¯ä¸ªæ—¶é—´æ­¥ä½œä¸ºç¼“å­˜èµ·ç‚¹çš„æ€»ä½“æ•ˆç‡
        cache_efficiency = []
        
        for i, t_start in enumerate(time_steps[:-1]):  # ä¸åŒ…æ‹¬æœ€åä¸€ä¸ªæ—¶é—´æ­¥
            efficiency_scores = []
            
            for j, t_end in enumerate(time_steps[i+1:], start=i+1):
                if t_start in trajectories_data and t_end in trajectories_data:
                    data_start = trajectories_data[t_start]
                    data_end = trajectories_data[t_end]
                    
                    # è®¡ç®—ç¼“å­˜æ•ˆç‡ = ç›¸ä¼¼æ€§ * ä»·å€¼æƒé‡ / æ—¶é—´æˆæœ¬
                    best_idx_start = np.argmax(data_start['values'])
                    best_idx_end = np.argmax(data_end['values'])
                    
                    mae_dist = mean_absolute_error(
                        data_start['trajectories'][best_idx_start],
                        data_end['trajectories'][best_idx_end]
                    )
                    similarity = 1 / (1 + mae_dist)
                    
                    # ä»·å€¼æƒé‡
                    value_weight = (data_start['values'][best_idx_start] + 
                                  data_end['values'][best_idx_end]) / 2
                    
                    # æ—¶é—´æˆæœ¬ (æ—¶é—´é—´éš”è¶Šå¤§æˆæœ¬è¶Šé«˜)
                    time_cost = 1 + (t_end - t_start) * 0.1
                    
                    efficiency = similarity * value_weight / time_cost
                    efficiency_scores.append(efficiency)
            
            avg_efficiency = np.mean(efficiency_scores) if efficiency_scores else 0
            cache_efficiency.append(avg_efficiency)
        
        if cache_efficiency:
            bars = ax4.bar(range(len(cache_efficiency)), cache_efficiency, 
                          color='lightcoral', alpha=0.7, edgecolor='black')
            
            # æ ‡è®°æœ€ä½³ç¼“å­˜æ—¶æœº
            best_cache_idx = np.argmax(cache_efficiency)
            bars[best_cache_idx].set_color('darkred')
            bars[best_cache_idx].set_alpha(1.0)
            
            ax4.set_xticks(range(len(cache_efficiency)))
            ax4.set_xticklabels([f't={time_steps[i]}' for i in range(len(cache_efficiency))])
            ax4.set_xlabel('ç¼“å­˜èµ·å§‹æ—¶é—´')
            ax4.set_ylabel('ç¼“å­˜æ•ˆç‡å¾—åˆ†')
            ax4.set_title('æœ€ä½³ç¼“å­˜æ—¶æœºåˆ†æ')
            
            # æ·»åŠ æœ€ä½³æ—¶æœºæ ‡æ³¨
            ax4.text(best_cache_idx, cache_efficiency[best_cache_idx] + 0.01,
                    'æœ€ä½³æ—¶æœº', ha='center', va='bottom', fontweight='bold',
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.8))
            
            ax4.grid(True, alpha=0.3, axis='y')
        
        plt.tight_layout()
        plt.suptitle('æ—¶åºé‡å çƒ­å›¾åˆ†æ - Cache MPC æœ€ä¼˜æ—¶æœº', fontsize=16, y=0.98)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        
        return fig

# ä½¿ç”¨ç¤ºä¾‹å’Œå®Œæ•´åˆ†ææµç¨‹
def run_complete_cache_mpc_analysis(test_dir, horizon=10, action_dim=4, episode_num=1):
    """è¿è¡Œå®Œæ•´çš„Cache MPCå¯è§†åŒ–åˆ†ææµç¨‹"""
    
    print("ğŸš€ å¼€å§‹Cache MPCè½¨è¿¹é‡å åˆ†æ...")
    
    # åˆå§‹åŒ–å¯è§†åŒ–å·¥å…·
    visualizer = CacheMPCVisualizer(horizon, action_dim)
    
    # åŠ è½½æ•°æ®
    print("ğŸ“Š åŠ è½½è½¨è¿¹æ•°æ®...")
    try:
        trajectories_data = visualizer.load_planned_actions_data(test_dir, episode_num)
        print(f"âœ“ æˆåŠŸåŠ è½½ {len(trajectories_data)} ä¸ªæ—¶é—´æ­¥çš„æ•°æ®")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    import os
    output_dir = f"{test_dir}/visualization_results"
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. è½¨è¿¹æŸå¯è§†åŒ–
    print("ğŸ¯ ç”Ÿæˆè½¨è¿¹æŸå¯è§†åŒ–...")
    bundle_fig = visualizer.trajectory_bundle_visualization(
        trajectories_data, 
        save_path=f"{output_dir}/trajectory_bundle_analysis.png"
    )
    
    # 2. ç›¸ä¼¼æ€§ç½‘ç»œå›¾
    print("ğŸ•¸ï¸ ç”Ÿæˆç›¸ä¼¼æ€§ç½‘ç»œå›¾...")
    network_fig = visualizer.similarity_network_visualization(
        trajectories_data,
        similarity_threshold=0.8,
        save_path=f"{output_dir}/similarity_network_analysis.png"
    )
    
    # 3. æ—¶åºé‡å çƒ­å›¾
    print("ğŸ”¥ ç”Ÿæˆæ—¶åºé‡å çƒ­å›¾...")
    heatmap_fig = visualizer.temporal_overlap_heatmap(
        trajectories_data,
        save_path=f"{output_dir}/temporal_overlap_heatmap.png"
    )
    
    print(f"âœ¨ åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {output_dir}")
    print("\nğŸ“‹ åˆ†ææŠ¥å‘Š:")
    print("1. trajectory_bundle_analysis.png - è½¨è¿¹æŸå¯è§†åŒ–")
    print("2. similarity_network_analysis.png - ç›¸ä¼¼æ€§ç½‘ç»œå›¾") 
    print("3. temporal_overlap_heatmap.png - æ—¶åºé‡å çƒ­å›¾")
    
    return {
        'bundle_fig': bundle_fig,
        'network_fig': network_fig, 
        'heatmap_fig': heatmap_fig,
        'data': trajectories_data
    }

# ä½¿ç”¨æŒ‡å—
if __name__ == "__main__":
    # ç¤ºä¾‹ä½¿ç”¨
    print("Cache MPC å¯è§†åŒ–å·¥å…·åŒ…")
    print("=" * 50)
    print("ä½¿ç”¨æ–¹æ³•:")
    print("1. ç¡®ä¿å·²è¿è¡Œtest.pyæ”¶é›†è½¨è¿¹æ•°æ®")
    print("2. è°ƒç”¨ run_complete_cache_mpc_analysis(test_dir, horizon, action_dim)")
    print("3. æŸ¥çœ‹ç”Ÿæˆçš„å¯è§†åŒ–ç»“æœ")
    print("\nå‚æ•°è¯´æ˜:")
    print("- test_dir: æµ‹è¯•æ•°æ®ç›®å½•è·¯å¾„")
    print("- horizon: è§„åˆ’åœ°å¹³çº¿é•¿åº¦") 
    print("- action_dim: åŠ¨ä½œç»´åº¦æ•°é‡")
    print("- episode_num: è¦åˆ†æçš„episodeç¼–å·")
    
    # ç¤ºä¾‹è°ƒç”¨ï¼ˆå–æ¶ˆæ³¨é‡Šä»¥ä½¿ç”¨ï¼‰
    # test_directory = "test/your_task/your_exp/your_seed/1"
    # results = run_complete_cache_mpc_analysis(test_directory, horizon=10, action_dim=4)
    
    plt.show()